{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "AQwydakla3yk"
      },
      "outputs": [],
      "source": [
        "!pip install \"chronos-forecasting[training] @ git+https://github.com/amazon-science/chronos-forecasting.git\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1hYq5pjVdRCF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pandas import DataFrame, Series\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "\n",
        "base_path = Path(__file__).parent\n",
        "CONFIG = {\n",
        "    'data_url': base_path / 'data/sp500_prices.csv',\n",
        "    'date_col': 'Date',\n",
        "    'price_col': 'Price'\n",
        "}\n",
        "\n",
        "def getDataFrame() -> DataFrame:\n",
        "    dataset = pd.read_csv(CONFIG['data_url'], parse_dates=[CONFIG['date_col']], index_col=CONFIG['date_col']).sort_index()\n",
        "    return dataset\n",
        "\n",
        "\n",
        "def getPrice(dataframe: DataFrame) -> Series:\n",
        "    return dataframe[CONFIG['price_col']]\n",
        "\n",
        "\n",
        "def calculateMAE(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Calculate the Mean Absolute Error between true and predicted values.\n",
        "\n",
        "    Args:\n",
        "        y_true: Array of actual/true values\n",
        "        y_pred: Array of predicted values\n",
        "\n",
        "    Returns:\n",
        "        float: Mean Absolute Error value\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If arrays are not 1-dimensional or have different lengths\n",
        "    \"\"\"\n",
        "\n",
        "    if y_true.ndim != 1 or y_pred.ndim != 1:\n",
        "        raise ValueError(\"Both arrays must be 1-dimensional.\")\n",
        "\n",
        "    if len(y_true) != len(y_pred):\n",
        "        raise ValueError(f\"Arrays must have the same length (y_true: {len(y_true)}, y_pred: {len(y_pred)})\")\n",
        "\n",
        "    return np.mean(np.abs(y_true - y_pred))\n",
        "\n",
        "\n",
        "def split_sequence(sequence, window_size, horizon):\n",
        "    \"\"\"\n",
        "    Split a time series sequence into input-output pairs for training.\n",
        "\n",
        "    Args:\n",
        "        sequence: List or array of sequential data points\n",
        "        window_size: Number of timesteps to use as input features\n",
        "        horizon: Number of timesteps to predict as output\n",
        "\n",
        "    Returns:\n",
        "        input_sequences: Array of input sequences, each of length window_size\n",
        "        output_sequences: Array of corresponding output sequences, each of length horizon\n",
        "    \"\"\"\n",
        "\n",
        "    X, y = [], []\n",
        "\n",
        "    for start_index in range(len(sequence)):\n",
        "        end_index = start_index + window_size\n",
        "        output_end_index = end_index + horizon\n",
        "\n",
        "        if output_end_index > len(sequence):\n",
        "            break\n",
        "\n",
        "        input_sequence = sequence[start_index:end_index]\n",
        "        output_sequence = sequence[end_index:output_end_index]\n",
        "\n",
        "        X.append(input_sequence)\n",
        "        y.append(output_sequence)\n",
        "\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "\n",
        "def split_train_test(raw_sequence, horizon):\n",
        "    \"\"\"\n",
        "    Split a time series sequence into training and test sets.\n",
        "\n",
        "    Args:\n",
        "        raw_sequence: Complete time series sequence\n",
        "        horizon: Number of timesteps to reserve for testing\n",
        "\n",
        "    Returns:\n",
        "        tuple: (train_seq, test_seq, split_idx) where split_idx is the index where split occurs\n",
        "    \"\"\"\n",
        "\n",
        "    split_idx = len(raw_sequence) - horizon\n",
        "    train_seq = raw_sequence[:split_idx]\n",
        "    test_seq = raw_sequence[split_idx:]\n",
        "    return train_seq, test_seq, split_idx\n",
        "\n",
        "\n",
        "def graph_comparison(title, dataset, mae, original, predictions, split_idx):\n",
        "    \"\"\"\n",
        "    Create visualization comparing original vs predicted values with two plots: full view and zoomed view.\n",
        "\n",
        "    Args:\n",
        "        title: Title for the plots\n",
        "        dataset: DataFrame containing the original data with date index\n",
        "        mae: Mean Absolute Error value to display on plots\n",
        "        original: Array of original/true values\n",
        "        predictions: Array of predicted values\n",
        "        split_idx: Index where training/test split occurs\n",
        "\n",
        "    Returns:\n",
        "        None: Displays two matplotlib plots\n",
        "    \"\"\"\n",
        "\n",
        "    date_index = dataset.index\n",
        "\n",
        "    plt.figure(figsize=(15, 5))\n",
        "\n",
        "    plt.plot(date_index, original, label='Original Price')\n",
        "\n",
        "    test_dates = date_index[split_idx:]\n",
        "    plt.plot(test_dates, predictions, label='Predicted Price')\n",
        "\n",
        "    plt.axvline(x=date_index[split_idx], color='r', linestyle='--', label='Train/Test Split')\n",
        "\n",
        "    plt.xlabel('Year')\n",
        "    plt.ylabel('Price')\n",
        "    plt.title(title)\n",
        "\n",
        "    start_date = date_index[len(date_index) - 3000]\n",
        "    end_date = date_index[-1]\n",
        "    plt.xlim(start_date, end_date)\n",
        "\n",
        "    # Format x-axis to show only years\n",
        "    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
        "    plt.gca().xaxis.set_major_locator(mdates.YearLocator())\n",
        "\n",
        "    plt.text(0.02, 0.95, f'MAE: {mae:.2f}', transform=plt.gca().transAxes,\n",
        "             bbox=dict(boxstyle='round,pad=0.3', facecolor='white', edgecolor='lightgray', alpha=0.9),\n",
        "             verticalalignment='top', fontsize=10, color='black')\n",
        "\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # === ZOOMED IN PLOT ===\n",
        "\n",
        "    plt.figure(figsize=(15, 5))\n",
        "\n",
        "    plt.plot(date_index, original, label='Original Price')\n",
        "    plt.plot(test_dates, predictions, label='Predicted Price')\n",
        "\n",
        "    plt.axvline(x=date_index[split_idx], color='r', linestyle='--', label='Train/Test Split')\n",
        "\n",
        "    plt.xlabel('Year')\n",
        "    plt.ylabel('Price')\n",
        "    plt.title(title)\n",
        "\n",
        "    start_date = date_index[len(date_index) - 1000]\n",
        "    end_date = date_index[-1]\n",
        "    plt.xlim(start_date, end_date)\n",
        "\n",
        "    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
        "    plt.gca().xaxis.set_major_locator(mdates.YearLocator())\n",
        "\n",
        "    plt.text(0.02, 0.95, f'MAE: {mae:.2f}', transform=plt.gca().transAxes,\n",
        "             bbox=dict(boxstyle='round,pad=0.3', facecolor='white', edgecolor='lightgray', alpha=0.9),\n",
        "             verticalalignment='top', fontsize=10, color='black')\n",
        "\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NACeAnnIcjr2"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from typing import List, Union\n",
        "\n",
        "import numpy as np\n",
        "from gluonts.dataset.arrow import ArrowWriter\n",
        "\n",
        "\n",
        "def convert_to_arrow(\n",
        "    path: Union[str, Path],\n",
        "    time_series: Union[List[np.ndarray], np.ndarray],\n",
        "    compression: str = \"lz4\",\n",
        "):\n",
        "    \"\"\"\n",
        "    Store a given set of series into Arrow format at the specified path.\n",
        "\n",
        "    Input data can be either a list of 1D numpy arrays, or a single 2D\n",
        "    numpy array of shape (num_series, time_length).\n",
        "    \"\"\"\n",
        "    assert isinstance(time_series, list) or (\n",
        "        isinstance(time_series, np.ndarray) and\n",
        "        time_series.ndim == 2\n",
        "    )\n",
        "\n",
        "    # Set an arbitrary start time\n",
        "    start = np.datetime64(\"2000-01-01 00:00\", \"s\")\n",
        "\n",
        "    dataset = [\n",
        "        {\"start\": start, \"target\": ts} for ts in time_series\n",
        "    ]\n",
        "\n",
        "    ArrowWriter(compression=compression).write_to_file(\n",
        "        dataset,\n",
        "        path=path,\n",
        "    )\n",
        "\n",
        "\n",
        "df = getDataFrame()\n",
        "price_series = getPrice(df)\n",
        "train_seq, test_seq, split_idx = split_train_test(price_series, 730)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    time_series = [train_seq]\n",
        "\n",
        "    # Convert to GluonTS arrow format\n",
        "    convert_to_arrow(\"./sp-data.arrow\", time_series=time_series)\n",
        "    print('done')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uh2AVlBwe25u"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/amazon-science/chronos-forecasting.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FxR70Uq0e8B-"
      },
      "outputs": [],
      "source": [
        "!CUDA_VISIBLE_DEVICES=0 python /content/chronos-forecasting/scripts/training/train.py --config /content/chronos-forecasting/scripts/training/configs/chronos-t5-small.yaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jT2t2abDod9h"
      },
      "outputs": [],
      "source": [
        "from chronos import BaseChronosPipeline\n",
        "\n",
        "pipeline = BaseChronosPipeline.from_pretrained(\"/content/output/run-0/checkpoint-final/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJIBnSIgzeTs"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "df = getDataFrame()\n",
        "\n",
        "quantiles, mean = pipeline.predict_quantiles(\n",
        "    context=torch.tensor(train_seq[-730:]),\n",
        "    prediction_length=730,\n",
        "    quantile_levels=[0.01, 0.05, 0.10, 0.20, 0.30, 0.40, 0.50, 0.60, 0.70, 0.75,\n",
        "                0.80, 0.85, 0.90, 0.93, 0.95, 0.97, 0.98, 0.99],\n",
        ")\n",
        "\n",
        "predictions = mean[0].numpy()\n",
        "mae = calculateMAE(test_seq, predictions)\n",
        "graph_comparison('S&P 500 Chronos-T5-Small (Fine-Tuned) Prediction', df, mae, df,\n",
        "                     predictions, split_idx)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
